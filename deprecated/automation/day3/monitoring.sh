#!/bin/bash
# Cloud Master Day3 - ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
# ê°•ì˜ì•ˆ ê¸°ë°˜ ì—…ë°ì´íŠ¸: 2024ë…„ 9ì›” 22ì¼

set -e

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

log_info "ğŸš€ Cloud Master Day3 - ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ìë™í™” ì‹œì‘"

# Prometheus ì„¤ì •
log_info "ğŸ“‹ Prometheus ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  - job_name: 'application'
    static_configs:
      - targets: ['application:3000']
    metrics_path: /metrics
    scrape_interval: 5s

  - job_name: 'jaeger'
    static_configs:
      - targets: ['jaeger:14269']
    metrics_path: /metrics

  - job_name: 'elasticsearch'
    static_configs:
      - targets: ['elasticsearch:9200']
    metrics_path: /_prometheus/metrics
EOF

log_success "Prometheus ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •
log_info "ğŸ“‹ Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > grafana-dashboard.json << 'EOF'
{
  "dashboard": {
    "id": null,
    "title": "Cloud Master Day3 - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ",
    "tags": ["cloud-master", "monitoring", "day3"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "CPU ì‚¬ìš©ë¥ ",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0},
        "targets": [
          {
            "expr": "100 - (avg by (instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU ì‚¬ìš©ë¥  %",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "ë°±ë¶„ìœ¨",
            "min": 0,
            "max": 100
          }
        ],
        "thresholds": [
          {
            "value": 80,
            "colorMode": "critical",
            "op": "gt"
          }
        ]
      },
      {
        "id": 2,
        "title": "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0},
        "targets": [
          {
            "expr": "100 - ((node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100)",
            "legendFormat": "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  %",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "ë°±ë¶„ìœ¨",
            "min": 0,
            "max": 100
          }
        ],
        "thresholds": [
          {
            "value": 90,
            "colorMode": "critical",
            "op": "gt"
          }
        ]
      },
      {
        "id": 3,
        "title": "HTTP ìš”ì²­ ìˆ˜",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8},
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "ìš”ì²­/ì´ˆ",
            "refId": "A"
          }
        ]
      },
      {
        "id": 4,
        "title": "ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ",
        "type": "graph",
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8},
        "targets": [
          {
            "expr": "100 - ((node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100)",
            "legendFormat": "ë””ìŠ¤í¬ ì‚¬ìš©ë¥  %",
            "refId": "A"
          }
        ],
        "yAxes": [
          {
            "label": "ë°±ë¶„ìœ¨",
            "min": 0,
            "max": 100
          }
        ]
      },
      {
        "id": 5,
        "title": "ë„¤íŠ¸ì›Œí¬ íŠ¸ë˜í”½",
        "type": "graph",
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 16},
        "targets": [
          {
            "expr": "rate(node_network_receive_bytes_total[5m])",
            "legendFormat": "ìˆ˜ì‹  {{device}}",
            "refId": "A"
          },
          {
            "expr": "rate(node_network_transmit_bytes_total[5m])",
            "legendFormat": "ì†¡ì‹  {{device}}",
            "refId": "B"
          }
        ]
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s",
    "annotations": {
      "list": [
        {
          "name": "ì•Œë¦¼",
          "enable": true,
          "iconColor": "rgba(0, 211, 255, 1)",
          "type": "dashboard"
        }
      ]
    }
  }
}
EOF

log_success "Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# Docker Compose ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì •
log_info "ğŸ“‹ Docker Compose ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > docker-compose.monitoring.yml << 'EOF'
version: '3.8'
services:
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert_rules.yml:/etc/prometheus/alert_rules.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    networks:
      - monitoring

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana-dashboard.json:/var/lib/grafana/dashboards/cloud-master-dashboard.json
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-piechart-panel
    networks:
      - monitoring
    depends_on:
      - prometheus

  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring

  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      - COLLECTOR_OTLP_ENABLED=true
    networks:
      - monitoring

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    networks:
      - monitoring

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - monitoring

  logstash:
    image: docker.elastic.co/logstash/logstash:7.15.0
    container_name: logstash
    ports:
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    networks:
      - monitoring
    depends_on:
      - elasticsearch

  kibana:
    image: docker.elastic.co/kibana/kibana:7.15.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - monitoring
    depends_on:
      - elasticsearch

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:
  elasticsearch_data:

networks:
  monitoring:
    driver: bridge
EOF

log_success "Docker Compose ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# Alert Manager ì„¤ì •
log_info "ğŸ“‹ Alert Manager ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > alertmanager.yml << 'EOF'
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@cloud-master.local'
  smtp_auth_username: 'alerts@cloud-master.local'
  smtp_auth_password: 'password'

route:
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'
  routes:
  - match:
      severity: critical
    receiver: 'critical-alerts'
  - match:
      severity: warning
    receiver: 'warning-alerts'

receivers:
- name: 'web.hook'
  webhook_configs:
  - url: 'http://127.0.0.1:5001/'
    send_resolved: true

- name: 'critical-alerts'
  webhook_configs:
  - url: 'http://127.0.0.1:5001/critical'
    send_resolved: true

- name: 'warning-alerts'
  webhook_configs:
  - url: 'http://127.0.0.1:5001/warning'
    send_resolved: true

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'cluster', 'service']
EOF

log_success "Alert Manager ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# Alert Rules ì„¤ì •
log_info "ğŸ“‹ Alert Rules ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > alert_rules.yml << 'EOF'
groups:
- name: cloud-master-app
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: critical
      service: web
    annotations:
      summary: "ë†’ì€ ì—ëŸ¬ìœ¨ ê°ì§€"
      description: "ì—ëŸ¬ìœ¨ì´ {{ $value }} errors/secë¡œ ë†’ìŠµë‹ˆë‹¤"

  - alert: HighCPUUsage
    expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
      service: system
    annotations:
      summary: "ë†’ì€ CPU ì‚¬ìš©ë¥  ê°ì§€"
      description: "CPU ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤"

  - alert: HighMemoryUsage
    expr: 100 - ((node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100) > 90
    for: 5m
    labels:
      severity: warning
      service: system
    annotations:
      summary: "ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ê°ì§€"
      description: "ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤"

  - alert: DiskSpaceLow
    expr: 100 - ((node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100) > 85
    for: 5m
    labels:
      severity: critical
      service: system
    annotations:
      summary: "ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡±"
      description: "ë””ìŠ¤í¬ ì‚¬ìš©ë¥ ì´ {{ $value }}%ì…ë‹ˆë‹¤"

  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
      service: application
    annotations:
      summary: "ì„œë¹„ìŠ¤ ë‹¤ìš´"
      description: "{{ $labels.job }} ì„œë¹„ìŠ¤ê°€ ë‹¤ìš´ë˜ì—ˆìŠµë‹ˆë‹¤"

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 1
    for: 5m
    labels:
      severity: warning
      service: web
    annotations:
      summary: "ë†’ì€ ì‘ë‹µ ì‹œê°„"
      description: "95% ì‘ë‹µ ì‹œê°„ì´ {{ $value }}ì´ˆì…ë‹ˆë‹¤"
EOF

log_success "Alert Rules ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# ELK Stack ì„¤ì •
log_info "ğŸ“‹ ELK Stack ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > docker-compose.logging.yml << 'EOF'
version: '3.8'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - logging
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: logstash
    ports:
      - "5044:5044"
      - "5000:5000"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - logstash_data:/usr/share/logstash/data
    networks:
      - logging
    depends_on:
      elasticsearch:
        condition: service_healthy
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
    networks:
      - logging
    depends_on:
      elasticsearch:
        condition: service_healthy

volumes:
  elasticsearch_data:
  logstash_data:

networks:
  logging:
    driver: bridge
EOF

log_success "ELK Stack ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# Logstash ì„¤ì •
log_info "ğŸ“‹ Logstash ì„¤ì • íŒŒì¼ ìƒì„± ì¤‘..."
cat > logstash.conf << 'EOF'
input {
  beats {
    port => 5044
  }
  
  tcp {
    port => 5000
    codec => json_lines
  }
  
  http {
    port => 8080
    codec => json
  }
}

filter {
  if [fields][service] == "web" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
  }
  
  if [fields][service] == "application" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{LOGLEVEL:level} %{GREEDYDATA:message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
    }
  }
  
  mutate {
    add_field => { "environment" => "cloud-master" }
    add_field => { "course" => "day3" }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "cloud-master-logs-%{+YYYY.MM.dd}"
    template_name => "cloud-master-logs"
    template => {
      "index_patterns" => ["cloud-master-logs-*"]
      "settings" => {
        "number_of_shards" => 1
        "number_of_replicas" => 0
      }
      "mappings" => {
        "properties" => {
          "@timestamp" => { "type" => "date" }
          "level" => { "type" => "keyword" }
          "message" => { "type" => "text" }
          "service" => { "type" => "keyword" }
          "environment" => { "type" => "keyword" }
          "course" => { "type" => "keyword" }
        }
      }
    }
  }
  
  stdout {
    codec => rubydebug
  }
}
EOF

log_success "Logstash ì„¤ì • íŒŒì¼ ìƒì„± ì™„ë£Œ"

# ëª¨ë‹ˆí„°ë§ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
log_info "ğŸ“‹ ëª¨ë‹ˆí„°ë§ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì¤‘..."
cat > start-monitoring.sh << 'EOF'
#!/bin/bash
# Cloud Master Day3 - ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸

set -e

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜
log_info() { echo -e "${BLUE}[INFO]${NC} $1"; }
log_success() { echo -e "${GREEN}[SUCCESS]${NC} $1"; }
log_warning() { echo -e "${YELLOW}[WARNING]${NC} $1"; }
log_error() { echo -e "${RED}[ERROR]${NC} $1"; }

log_info "ğŸš€ Cloud Master Day3 ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘ ì¤‘..."

# Docker ì„¤ì¹˜ í™•ì¸
if ! command -v docker &> /dev/null; then
    log_error "Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € Dockerë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”."
    exit 1
fi

if ! command -v docker-compose &> /dev/null; then
    log_error "Docker Composeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € Docker Composeë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”."
    exit 1
fi

# ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘
log_info "ğŸ“Š ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘ ì¤‘..."
docker-compose -f docker-compose.monitoring.yml up -d

# ë¡œê¹… ìŠ¤íƒ ì‹œì‘
log_info "ğŸ“ ë¡œê¹… ìŠ¤íƒ ì‹œì‘ ì¤‘..."
docker-compose -f docker-compose.logging.yml up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
log_info "ğŸ” ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì¤‘..."
sleep 10

# Prometheus ìƒíƒœ í™•ì¸
if curl -f -s http://localhost:9090/-/healthy > /dev/null; then
    log_success "âœ… Prometheus ì •ìƒ ì‘ë™"
else
    log_warning "âš ï¸ Prometheus ìƒíƒœ í™•ì¸ ì‹¤íŒ¨"
fi

# Grafana ìƒíƒœ í™•ì¸
if curl -f -s http://localhost:3001/api/health > /dev/null; then
    log_success "âœ… Grafana ì •ìƒ ì‘ë™"
else
    log_warning "âš ï¸ Grafana ìƒíƒœ í™•ì¸ ì‹¤íŒ¨"
fi

# Jaeger ìƒíƒœ í™•ì¸
if curl -f -s http://localhost:16686/api/services > /dev/null; then
    log_success "âœ… Jaeger ì •ìƒ ì‘ë™"
else
    log_warning "âš ï¸ Jaeger ìƒíƒœ í™•ì¸ ì‹¤íŒ¨"
fi

# Kibana ìƒíƒœ í™•ì¸
if curl -f -s http://localhost:5601/api/status > /dev/null; then
    log_success "âœ… Kibana ì •ìƒ ì‘ë™"
else
    log_warning "âš ï¸ Kibana ìƒíƒœ í™•ì¸ ì‹¤íŒ¨"
fi

log_success "ğŸ‰ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘ ì™„ë£Œ!"
echo ""
echo "ğŸ“Š ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì ‘ì† ì •ë³´:"
echo "  â€¢ Prometheus: http://localhost:9090"
echo "  â€¢ Grafana: http://localhost:3001 (admin/admin)"
echo "  â€¢ Jaeger: http://localhost:16686"
echo "  â€¢ Kibana: http://localhost:5601"
echo "  â€¢ Alertmanager: http://localhost:9093"
echo ""
echo "ğŸ“ ë¡œê¹… ë„êµ¬ ì ‘ì† ì •ë³´:"
echo "  â€¢ Elasticsearch: http://localhost:9200"
echo "  â€¢ Logstash: http://localhost:5044 (Beats), http://localhost:5000 (TCP), http://localhost:8080 (HTTP)"
echo ""
echo "ğŸ”§ ìœ ìš©í•œ ëª…ë ¹ì–´:"
echo "  â€¢ ë¡œê·¸ í™•ì¸: docker-compose -f docker-compose.monitoring.yml logs -f"
echo "  â€¢ ì„œë¹„ìŠ¤ ì¤‘ì§€: docker-compose -f docker-compose.monitoring.yml down"
echo "  â€¢ ë°ì´í„° ì •ë¦¬: docker-compose -f docker-compose.monitoring.yml down -v"
EOF

chmod +x start-monitoring.sh

log_success "ëª¨ë‹ˆí„°ë§ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸ ìƒì„± ì™„ë£Œ"

# ìµœì¢… ìš”ì•½
log_success "ğŸ‰ Cloud Master Day3 ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì • ì™„ë£Œ!"
echo ""
echo "ğŸ“‹ ìƒì„±ëœ íŒŒì¼ë“¤:"
echo "  â€¢ prometheus.yml - Prometheus ì„¤ì •"
echo "  â€¢ grafana-dashboard.json - Grafana ëŒ€ì‹œë³´ë“œ"
echo "  â€¢ docker-compose.monitoring.yml - ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ"
echo "  â€¢ alertmanager.yml - Alert Manager ì„¤ì •"
echo "  â€¢ alert_rules.yml - ì•Œë¦¼ ê·œì¹™"
echo "  â€¢ docker-compose.logging.yml - ELK ìŠ¤íƒ"
echo "  â€¢ logstash.conf - Logstash ì„¤ì •"
echo "  â€¢ start-monitoring.sh - ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸"
echo ""
echo "ğŸš€ ì‚¬ìš©ë²•:"
echo "  ./start-monitoring.sh"
echo ""
echo "ğŸ“Š ì ‘ì† ì •ë³´:"
echo "  â€¢ Prometheus: http://localhost:9090"
echo "  â€¢ Grafana: http://localhost:3001 (admin/admin)"
echo "  â€¢ Jaeger: http://localhost:16686"
echo "  â€¢ Kibana: http://localhost:5601"
echo "  â€¢ Alertmanager: http://localhost:9093"
