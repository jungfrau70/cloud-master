#!/bin/bash

# Cloud Master Day 3 - Monitoring Practice Automation Script
# ì‘ì„±ì: Cloud Master Team
# ëª©ì : ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹… ì‹œìŠ¤í…œ ì‹¤ìŠµ ìë™í™”

set -e  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# ë¡œê·¸ í•¨ìˆ˜
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ì‹¤ìŠµ í™˜ê²½ í™•ì¸
check_prerequisites() {
    log_info "ì‹¤ìŠµ í™˜ê²½ í™•ì¸ ì¤‘..."
    
    # Docker ì„¤ì¹˜ í™•ì¸
    if ! command -v docker &> /dev/null; then
        log_error "Dockerê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë¨¼ì € Dockerë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        exit 1
    fi
    
    # Docker Compose ì„¤ì¹˜ í™•ì¸
    if ! command -v docker-compose &> /dev/null; then
        log_warning "Docker Composeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì„¤ì¹˜ë¥¼ ì‹œë„í•©ë‹ˆë‹¤."
        install_docker_compose
    fi
    
    # AWS CLI ì„¤ì¹˜ í™•ì¸
    if ! command -v aws &> /dev/null; then
        log_warning "AWS CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ì„¤ì¹˜ë¥¼ ì‹œë„í•©ë‹ˆë‹¤."
        install_aws_cli
    fi
    
    log_success "ì‹¤ìŠµ í™˜ê²½ í™•ì¸ ì™„ë£Œ"
}

# Docker Compose ì„¤ì¹˜
install_docker_compose() {
    log_info "Docker Compose ì„¤ì¹˜ ì¤‘..."
    
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        sudo chmod +x /usr/local/bin/docker-compose
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        if command -v brew &> /dev/null; then
            brew install docker-compose
        else
            log_error "Homebrewê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Docker Composeë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
            exit 1
        fi
    else
        log_error "ì§€ì›ë˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤. Docker Composeë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        exit 1
    fi
    
    log_success "Docker Compose ì„¤ì¹˜ ì™„ë£Œ"
}

# AWS CLI ì„¤ì¹˜
install_aws_cli() {
    log_info "AWS CLI ì„¤ì¹˜ ì¤‘..."
    
    if [[ "$OSTYPE" == "linux-gnu"* ]]; then
        # Linux
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip awscliv2.zip
        sudo ./aws/install
        rm -rf aws awscliv2.zip
    elif [[ "$OSTYPE" == "darwin"* ]]; then
        # macOS
        if command -v brew &> /dev/null; then
            brew install awscli
        else
            curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"
            sudo installer -pkg AWSCLIV2.pkg -target /
            rm AWSCLIV2.pkg
        fi
    else
        log_error "ì§€ì›ë˜ì§€ ì•ŠëŠ” ìš´ì˜ì²´ì œì…ë‹ˆë‹¤. AWS CLIë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        exit 1
    fi
    
    log_success "AWS CLI ì„¤ì¹˜ ì™„ë£Œ"
}

# 1ë‹¨ê³„: Prometheus & Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì •
step1_prometheus_grafana_setup() {
    log_info "=== 1ë‹¨ê³„: Prometheus & Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì • ==="
    
    # ì‹¤ìŠµìš© ë””ë ‰í† ë¦¬ ìƒì„±
    log_info "ì‹¤ìŠµìš© ë””ë ‰í† ë¦¬ ìƒì„±:"
    mkdir -p ~/monitoring-practice
    cd ~/monitoring-practice
    
    # ê¸°ì¡´ ì»¨í…Œì´ë„ˆ ì •ë¦¬
    log_info "ê¸°ì¡´ ëª¨ë‹ˆí„°ë§ ì»¨í…Œì´ë„ˆ ì •ë¦¬:"
    docker-compose down 2>/dev/null || true
    
    # Docker Compose íŒŒì¼ ìƒì„±
    log_info "Docker Compose íŒŒì¼ ìƒì„±:"
    cat > docker-compose.yml << 'EOF'
version: '3.8'

services:
  # Prometheus - ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
    networks:
      - monitoring

  # Grafana - ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - monitoring

  # Node Exporter - ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  node-exporter:
    image: prom/node-exporter:latest
    container_name: node-exporter
    ports:
      - "9100:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    networks:
      - monitoring

  # cAdvisor - ì»¨í…Œì´ë„ˆ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "8080:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    privileged: true
    devices:
      - /dev/kmsg
    networks:
      - monitoring

  # AlertManager - ì•Œë¦¼ ê´€ë¦¬
  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    networks:
      - monitoring

  # í…ŒìŠ¤íŠ¸ìš© ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
  web-app:
    image: nginx:alpine
    container_name: web-app
    ports:
      - "80:80"
    networks:
      - monitoring

volumes:
  prometheus_data:
  grafana_data:
  alertmanager_data:

networks:
  monitoring:
    driver: bridge
EOF
    
    # Prometheus ì„¤ì • íŒŒì¼ ìƒì„±
    log_info "Prometheus ì„¤ì • íŒŒì¼ ìƒì„±:"
    cat > prometheus.yml << 'EOF'
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  - "alert_rules.yml"

alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']

  - job_name: 'cadvisor'
    static_configs:
      - targets: ['cadvisor:8080']

  - job_name: 'web-app'
    static_configs:
      - targets: ['web-app:80']
EOF
    
    # AlertManager ì„¤ì • íŒŒì¼ ìƒì„±
    log_info "AlertManager ì„¤ì • íŒŒì¼ ìƒì„±:"
    cat > alertmanager.yml << 'EOF'
global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alertmanager@example.com'

route:
  group_by: ['alertname']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'web.hook'

receivers:
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://127.0.0.1:5001/'

inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'dev', 'instance']
EOF
    
    # Grafana í”„ë¡œë¹„ì €ë‹ ë””ë ‰í† ë¦¬ ìƒì„±
    log_info "Grafana í”„ë¡œë¹„ì €ë‹ ì„¤ì • ìƒì„±:"
    mkdir -p grafana/provisioning/datasources
    mkdir -p grafana/provisioning/dashboards
    
    # Prometheus ë°ì´í„°ì†ŒìŠ¤ ì„¤ì •
    cat > grafana/provisioning/datasources/prometheus.yml << 'EOF'
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
EOF
    
    # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘
    log_info "ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì‹œì‘:"
    docker-compose up -d
    
    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    log_info "ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸:"
    docker-compose ps
    
    # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
    log_info "ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸° (60ì´ˆ)..."
    sleep 60
    
    # ì„œë¹„ìŠ¤ ìƒíƒœ ì¬í™•ì¸
    log_info "ì„œë¹„ìŠ¤ ìƒíƒœ ì¬í™•ì¸:"
    docker-compose ps
    
    log_success "1ë‹¨ê³„ ì™„ë£Œ: Prometheus & Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ì„¤ì •"
}

# 2ë‹¨ê³„: CloudWatch ëª¨ë‹ˆí„°ë§ ì„¤ì •
step2_cloudwatch_setup() {
    log_info "=== 2ë‹¨ê³„: CloudWatch ëª¨ë‹ˆí„°ë§ ì„¤ì • ==="
    
    # AWS CLI ì„¤ì • í™•ì¸
    log_info "AWS CLI ì„¤ì • í™•ì¸:"
    if ! aws sts get-caller-identity &> /dev/null; then
        log_warning "AWS CLIê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. AWS ìê²© ì¦ëª…ì„ ì„¤ì •í•´ì£¼ì„¸ìš”."
        log_info "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ AWS ìê²© ì¦ëª…ì„ ì„¤ì •í•˜ì„¸ìš”:"
        echo "  aws configure"
        echo "  AWS Access Key ID: YOUR_ACCESS_KEY"
        echo "  AWS Secret Access Key: YOUR_SECRET_KEY"
        echo "  Default region name: ap-northeast-2"
        echo "  Default output format: json"
        log_warning "AWS ì„¤ì •ì„ ì™„ë£Œí•œ í›„ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”."
        return
    fi
    
    # AWS ê³„ì • ì •ë³´ í™•ì¸
    log_info "AWS ê³„ì • ì •ë³´ í™•ì¸:"
    aws sts get-caller-identity
    
    # CloudWatch ëŒ€ì‹œë³´ë“œ ìƒì„±
    log_info "CloudWatch ëŒ€ì‹œë³´ë“œ ìƒì„±:"
    cat > cloudwatch-dashboard.json << 'EOF'
{
  "widgets": [
    {
      "type": "metric",
      "x": 0,
      "y": 0,
      "width": 12,
      "height": 6,
      "properties": {
        "metrics": [
          [ "AWS/EC2", "CPUUtilization" ],
          [ ".", "NetworkIn" ],
          [ ".", "NetworkOut" ]
        ],
        "view": "timeSeries",
        "stacked": false,
        "region": "ap-northeast-2",
        "title": "EC2 Metrics",
        "period": 300
      }
    },
    {
      "type": "metric",
      "x": 12,
      "y": 0,
      "width": 12,
      "height": 6,
      "properties": {
        "metrics": [
          [ "AWS/EC2", "DiskReadOps" ],
          [ ".", "DiskWriteOps" ]
        ],
        "view": "timeSeries",
        "stacked": false,
        "region": "ap-northeast-2",
        "title": "Disk Operations",
        "period": 300
      }
    }
  ]
}
EOF
    
    # CloudWatch ëŒ€ì‹œë³´ë“œ í™•ì¸ ë° ìƒì„±
    log_info "CloudWatch ëŒ€ì‹œë³´ë“œ í™•ì¸:"
    if aws cloudwatch get-dashboard --dashboard-name "CloudMaster-Practice" &> /dev/null; then
        log_info "CloudMaster-Practice ëŒ€ì‹œë³´ë“œê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
    else
        log_info "CloudWatch ëŒ€ì‹œë³´ë“œ ìƒì„±:"
        aws cloudwatch put-dashboard \
            --dashboard-name "CloudMaster-Practice" \
            --dashboard-body file://cloudwatch-dashboard.json
    fi
    
    # ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì „ì†¡
    log_info "ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ ì „ì†¡:"
    aws cloudwatch put-metric-data \
        --namespace "CloudMaster/Practice" \
        --metric-data MetricName=CustomMetric,Value=1.0,Unit=Count
    
    # ë©”íŠ¸ë¦­ í™•ì¸
    log_info "ë©”íŠ¸ë¦­ í™•ì¸:"
    aws cloudwatch list-metrics --namespace "CloudMaster/Practice"
    
    # CloudWatch ë¡œê·¸ ê·¸ë£¹ í™•ì¸ ë° ìƒì„±
    log_info "CloudWatch ë¡œê·¸ ê·¸ë£¹ í™•ì¸:"
    if aws logs describe-log-groups --log-group-name-prefix "/cloudmaster/practice" --query 'logGroups[0].logGroupName' --output text | grep -q "/cloudmaster/practice"; then
        log_info "ë¡œê·¸ ê·¸ë£¹ /cloudmaster/practiceê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
    else
        log_info "CloudWatch ë¡œê·¸ ê·¸ë£¹ ìƒì„±:"
        aws logs create-log-group --log-group-name "/cloudmaster/practice"
    fi
    
    # ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ í™•ì¸ ë° ìƒì„±
    log_info "ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ í™•ì¸:"
    if aws logs describe-log-streams --log-group-name "/cloudmaster/practice" --log-stream-name-prefix "application-logs" --query 'logStreams[0].logStreamName' --output text | grep -q "application-logs"; then
        log_info "ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ application-logsê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤."
    else
        log_info "ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±:"
        aws logs create-log-stream \
            --log-group-name "/cloudmaster/practice" \
            --log-stream-name "application-logs"
    fi
    
    # ë¡œê·¸ ì´ë²¤íŠ¸ ì „ì†¡
    log_info "ë¡œê·¸ ì´ë²¤íŠ¸ ì „ì†¡:"
    aws logs put-log-events \
        --log-group-name "/cloudmaster/practice" \
        --log-stream-name "application-logs" \
        --log-events timestamp=$(date +%s)000,message="CloudMaster Practice Log Entry"
    
    log_success "2ë‹¨ê³„ ì™„ë£Œ: CloudWatch ëª¨ë‹ˆí„°ë§ ì„¤ì •"
}

# 3ë‹¨ê³„: ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ (ELK Stack)
step3_elk_stack_setup() {
    log_info "=== 3ë‹¨ê³„: ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ (ELK Stack) ==="
    
    # ELK Stack Docker Compose íŒŒì¼ ìƒì„±
    log_info "ELK Stack Docker Compose íŒŒì¼ ìƒì„±:"
    cat > elk-compose.yml << 'EOF'
version: '3.8'

services:
  # Elasticsearch - ë¡œê·¸ ì €ì¥ ë° ê²€ìƒ‰
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - elk

  # Kibana - ë¡œê·¸ ì‹œê°í™”
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - elk

  # Logstash - ë¡œê·¸ ì²˜ë¦¬
  logstash:
    image: docker.elastic.co/logstash/logstash:8.8.0
    container_name: logstash
    ports:
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    networks:
      - elk

  # Filebeat - ë¡œê·¸ ìˆ˜ì§‘
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.8.0
    container_name: filebeat
    user: root
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      - logstash
    networks:
      - elk

volumes:
  elasticsearch_data:

networks:
  elk:
    driver: bridge
EOF
    
    # Logstash ì„¤ì • íŒŒì¼ ìƒì„±
    log_info "Logstash ì„¤ì • íŒŒì¼ ìƒì„±:"
    cat > logstash.conf << 'EOF'
input {
  beats {
    port => 5044
  }
}

filter {
  if [fields][service] == "nginx" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
  }
  
  if [fields][service] == "application" {
    json {
      source => "message"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
  }
}
EOF
    
    # Filebeat ì„¤ì • íŒŒì¼ ìƒì„±
    log_info "Filebeat ì„¤ì • íŒŒì¼ ìƒì„±:"
    cat > filebeat.yml << 'EOF'
filebeat.inputs:
- type: container
  paths:
    - '/var/lib/docker/containers/*/*.log'
  processors:
  - add_docker_metadata:
      host: "unix:///var/run/docker.sock"
  - add_fields:
      fields:
        service: "docker"

output.logstash:
  hosts: ["logstash:5044"]

logging.level: info
EOF
    
    # ELK Stack ì‹œì‘
    log_info "ELK Stack ì‹œì‘:"
    docker-compose -f elk-compose.yml up -d
    
    # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    log_info "ELK Stack ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸:"
    docker-compose -f elk-compose.yml ps
    
    # ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸°
    log_info "ELK Stack ì„œë¹„ìŠ¤ ì‹œì‘ ëŒ€ê¸° (60ì´ˆ)..."
    sleep 60
    
    # Elasticsearch ìƒíƒœ í™•ì¸
    log_info "Elasticsearch ìƒíƒœ í™•ì¸:"
    curl -s http://localhost:9200 | head -5
    
    log_success "3ë‹¨ê³„ ì™„ë£Œ: ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ (ELK Stack)"
}

# 4ë‹¨ê³„: ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§
step4_application_monitoring() {
    log_info "=== 4ë‹¨ê³„: ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§ ==="
    
    # ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±
    log_info "ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒì„±:"
    cat > app-compose.yml << 'EOF'
version: '3.8'

services:
  # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
  web-app:
    build: .
    container_name: monitored-web-app
    ports:
      - "8080:3000"
    environment:
      - NODE_ENV=production
      - METRICS_PORT=9090
    networks:
      - monitoring
      - elk

  # Prometheus Node Exporter
  node-exporter:
    image: prom/node-exporter:latest
    container_name: app-node-exporter
    ports:
      - "9101:9100"
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
    networks:
      - monitoring

networks:
  monitoring:
    external: true
  elk:
    external: true
EOF
    
    # Dockerfile ìƒì„±
    log_info "ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ Dockerfile ìƒì„±:"
    cat > Dockerfile << 'EOF'
FROM node:18-alpine

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY package*.json ./
RUN npm ci --only=production

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 3000 9090

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
CMD ["npm", "start"]
EOF
    
    # package.json ìƒì„±
    log_info "package.json ìƒì„±:"
    cat > package.json << 'EOF'
{
  "name": "monitored-web-app",
  "version": "1.0.0",
  "description": "Web application with monitoring capabilities",
  "main": "server.js",
  "scripts": {
    "start": "node server.js"
  },
  "dependencies": {
    "express": "^4.18.0",
    "prom-client": "^14.0.0"
  }
}
EOF
    
    # ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì„œë²„ ì½”ë“œ ìƒì„±
    log_info "ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥í•œ ì„œë²„ ì½”ë“œ ìƒì„±:"
    cat > server.js << 'EOF'
const express = require('express');
const client = require('prom-client');

const app = express();
const port = process.env.PORT || 3000;
const metricsPort = process.env.METRICS_PORT || 9090;

// Prometheus ë©”íŠ¸ë¦­ ì„¤ì •
const register = new client.Registry();

// ê¸°ë³¸ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
client.collectDefaultMetrics({ register });

// ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­
const httpRequestDuration = new client.Histogram({
  name: 'http_request_duration_seconds',
  help: 'Duration of HTTP requests in seconds',
  labelNames: ['method', 'route', 'status_code'],
  buckets: [0.1, 0.3, 0.5, 0.7, 1, 3, 5, 7, 10]
});

const httpRequestTotal = new client.Counter({
  name: 'http_requests_total',
  help: 'Total number of HTTP requests',
  labelNames: ['method', 'route', 'status_code']
});

const activeConnections = new client.Gauge({
  name: 'active_connections',
  help: 'Number of active connections'
});

register.registerMetric(httpRequestDuration);
register.registerMetric(httpRequestTotal);
register.registerMetric(activeConnections);

// ë¯¸ë“¤ì›¨ì–´
app.use(express.json());

// ìš”ì²­ ë¡œê¹… ë¯¸ë“¤ì›¨ì–´
app.use((req, res, next) => {
  const start = Date.now();
  
  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000;
    const labels = {
      method: req.method,
      route: req.route ? req.route.path : req.path,
      status_code: res.statusCode
    };
    
    httpRequestDuration.observe(labels, duration);
    httpRequestTotal.inc(labels);
  });
  
  next();
});

// ë¼ìš°íŠ¸
app.get('/', (req, res) => {
  res.json({
    message: 'Monitored Web Application',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    version: '1.0.0'
  });
});

app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    timestamp: new Date().toISOString(),
    uptime: process.uptime()
  });
});

app.get('/metrics', (req, res) => {
  res.set('Content-Type', register.contentType);
  res.end(register.metrics());
});

app.get('/api/data', (req, res) => {
  // ì‹œë®¬ë ˆì´ì…˜ëœ ë°ì´í„° ì²˜ë¦¬
  const data = {
    id: Math.floor(Math.random() * 1000),
    value: Math.random() * 100,
    timestamp: new Date().toISOString()
  };
  
  res.json(data);
});

app.get('/api/error', (req, res) => {
  res.status(500).json({
    error: 'Simulated error for testing',
    timestamp: new Date().toISOString()
  });
});

// ì„œë²„ ì‹œì‘
app.listen(port, () => {
  console.log(`Web application running on port ${port}`);
  console.log(`Metrics available at http://localhost:${port}/metrics`);
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('SIGTERM received, shutting down gracefully');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('SIGINT received, shutting down gracefully');
  process.exit(0);
});
EOF
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ë¹Œë“œ ë° ì‹¤í–‰
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ ë¹Œë“œ ë° ì‹¤í–‰:"
    docker-compose -f app-compose.yml up -d --build
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ í™•ì¸
    log_info "ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ í™•ì¸:"
    sleep 10
    curl -s http://localhost:8080 | head -5
    curl -s http://localhost:8080/health
    curl -s http://localhost:8080/metrics | head -10
    
    log_success "4ë‹¨ê³„ ì™„ë£Œ: ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§"
}

# 5ë‹¨ê³„: ì•Œë¦¼ ì„¤ì • ë° í…ŒìŠ¤íŠ¸
step5_alerting_setup() {
    log_info "=== 5ë‹¨ê³„: ì•Œë¦¼ ì„¤ì • ë° í…ŒìŠ¤íŠ¸ ==="
    
    # Prometheus ì•Œë¦¼ ê·œì¹™ ìƒì„±
    log_info "Prometheus ì•Œë¦¼ ê·œì¹™ ìƒì„±:"
    cat > alert_rules.yml << 'EOF'
groups:
- name: cloudmaster.rules
  rules:
  - alert: HighCPUUsage
    expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High CPU usage detected"
      description: "CPU usage is above 80% for more than 5 minutes"

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "High memory usage detected"
      description: "Memory usage is above 85% for more than 5 minutes"

  - alert: ServiceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
    annotations:
      summary: "Service is down"
      description: "Service {{ $labels.instance }} has been down for more than 1 minute"

  - alert: HighErrorRate
    expr: rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "High error rate detected"
      description: "Error rate is above 5% for more than 5 minutes"
EOF
    
    # Prometheus ì„¤ì • ì—…ë°ì´íŠ¸
    log_info "Prometheus ì„¤ì • ì—…ë°ì´íŠ¸:"
    docker-compose restart prometheus
    
    # ì•Œë¦¼ ê·œì¹™ í™•ì¸
    log_info "ì•Œë¦¼ ê·œì¹™ í™•ì¸:"
    sleep 10
    curl -s http://localhost:9090/api/v1/rules | head -5
    
    # AlertManager ìƒíƒœ í™•ì¸
    log_info "AlertManager ìƒíƒœ í™•ì¸:"
    curl -s http://localhost:9093/api/v1/status | head -5
    
    log_success "5ë‹¨ê³„ ì™„ë£Œ: ì•Œë¦¼ ì„¤ì • ë° í…ŒìŠ¤íŠ¸"
}

# 6ë‹¨ê³„: ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì„¤ì •
step6_dashboard_setup() {
    log_info "=== 6ë‹¨ê³„: ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì„¤ì • ==="
    
    # Grafana ëŒ€ì‹œë³´ë“œ JSON ìƒì„±
    log_info "Grafana ëŒ€ì‹œë³´ë“œ JSON ìƒì„±:"
    cat > grafana-dashboard.json << 'EOF'
{
  "dashboard": {
    "id": null,
    "title": "CloudMaster Practice Dashboard",
    "tags": ["cloudmaster", "practice"],
    "style": "dark",
    "timezone": "browser",
    "panels": [
      {
        "id": 1,
        "title": "CPU Usage",
        "type": "stat",
        "targets": [
          {
            "expr": "100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Memory Usage",
        "type": "stat",
        "targets": [
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "Memory Usage %"
          }
        ],
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
      },
      {
        "id": 3,
        "title": "HTTP Requests",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total[5m])",
            "legendFormat": "{{method}} {{route}}"
          }
        ],
        "gridPos": {"h": 8, "w": 24, "x": 0, "y": 8}
      }
    ],
    "time": {
      "from": "now-1h",
      "to": "now"
    },
    "refresh": "5s"
  }
}
EOF
    
    # ëŒ€ì‹œë³´ë“œ ê°€ì ¸ì˜¤ê¸°
    log_info "Grafana ëŒ€ì‹œë³´ë“œ ê°€ì ¸ì˜¤ê¸°:"
    curl -X POST \
      http://admin:admin123@localhost:3000/api/dashboards/db \
      -H 'Content-Type: application/json' \
      -d @grafana-dashboard.json
    
    log_success "6ë‹¨ê³„ ì™„ë£Œ: ëŒ€ì‹œë³´ë“œ ìƒì„± ë° ì„¤ì •"
}

# 7ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦
step7_monitoring_test() {
    log_info "=== 7ë‹¨ê³„: ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ==="
    
    # ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸
    log_info "ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¶€í•˜ í…ŒìŠ¤íŠ¸:"
    for i in {1..100}; do
        curl -s http://localhost:8080/api/data > /dev/null &
        curl -s http://localhost:8080/health > /dev/null &
        if [ $((i % 10)) -eq 0 ]; then
            sleep 1
        fi
    done
    
    # ì—ëŸ¬ ì‹œë®¬ë ˆì´ì…˜
    log_info "ì—ëŸ¬ ì‹œë®¬ë ˆì´ì…˜:"
    for i in {1..10}; do
        curl -s http://localhost:8080/api/error > /dev/null &
    done
    
    # ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
    log_info "ëª¨ë‹ˆí„°ë§ ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸:"
    echo "=== Prometheus ==="
    curl -s http://localhost:9090/api/v1/targets | head -5
    
    echo "=== Grafana ==="
    curl -s http://localhost:3000/api/health | head -5
    
    echo "=== Elasticsearch ==="
    curl -s http://localhost:9200/_cluster/health | head -5
    
    echo "=== Kibana ==="
    curl -s http://localhost:5601/api/status | head -5
    
    log_success "7ë‹¨ê³„ ì™„ë£Œ: ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦"
}

# 8ë‹¨ê³„: ì •ë¦¬ ë° ìš”ì•½
step8_cleanup_and_summary() {
    log_info "=== 8ë‹¨ê³„: ì •ë¦¬ ë° ìš”ì•½ ==="
    
    # ëª¨ë“  ì„œë¹„ìŠ¤ ì¤‘ì§€
    log_info "ëª¨ë“  ì„œë¹„ìŠ¤ ì¤‘ì§€:"
    docker-compose down
    docker-compose -f elk-compose.yml down
    docker-compose -f app-compose.yml down
    
    # ë³¼ë¥¨ ì •ë¦¬ (ì„ íƒì‚¬í•­)
    log_warning "ë³¼ë¥¨ ì •ë¦¬ (ì„ íƒì‚¬í•­):"
    echo "ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë³¼ë¥¨ì„ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:"
    echo "  docker volume prune"
    
    # ì‹¤ìŠµ ê²°ê³¼ ìš”ì•½
    log_success "=== ëª¨ë‹ˆí„°ë§ ì‹¤ìŠµ ì™„ë£Œ ==="
    echo "âœ… Prometheus & Grafana ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ"
    echo "âœ… CloudWatch ëŒ€ì‹œë³´ë“œ ë° ë©”íŠ¸ë¦­"
    echo "âœ… ELK Stack ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„"
    echo "âœ… ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§ ì„¤ì •"
    echo "âœ… ì•Œë¦¼ ê·œì¹™ ë° AlertManager"
    echo "âœ… Grafana ëŒ€ì‹œë³´ë“œ ìƒì„±"
    echo "âœ… ëª¨ë‹ˆí„°ë§ í…ŒìŠ¤íŠ¸ ë° ê²€ì¦"
    echo ""
    echo "ğŸŒ ì ‘ì† ê°€ëŠ¥í•œ ì„œë¹„ìŠ¤:"
    echo "  - Prometheus: http://localhost:9090"
    echo "  - Grafana: http://localhost:3000 (admin/admin123)"
    echo "  - Elasticsearch: http://localhost:9200"
    echo "  - Kibana: http://localhost:5601"
    echo "  - AlertManager: http://localhost:9093"
    echo "  - ëª¨ë‹ˆí„°ë§ ì•±: http://localhost:8080"
    echo ""
    echo "ğŸ“Š ì£¼ìš” í•™ìŠµ ë‚´ìš©:"
    echo "  - ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥ (Prometheus)"
    echo "  - ì‹œê°í™” ë° ëŒ€ì‹œë³´ë“œ (Grafana)"
    echo "  - ë¡œê·¸ ìˆ˜ì§‘ ë° ë¶„ì„ (ELK Stack)"
    echo "  - í´ë¼ìš°ë“œ ëª¨ë‹ˆí„°ë§ (CloudWatch)"
    echo "  - ì•Œë¦¼ ì„¤ì • ë° ê´€ë¦¬"
    echo "  - ì• í”Œë¦¬ì¼€ì´ì…˜ ëª¨ë‹ˆí„°ë§"
}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
main() {
    log_info "Cloud Master Day 3 - Monitoring Practice Automation ì‹œì‘"
    echo "================================================================="
    
    check_prerequisites
    step1_prometheus_grafana_setup
    step2_cloudwatch_setup
    step3_elk_stack_setup
    step4_application_monitoring
    step5_alerting_setup
    step6_dashboard_setup
    step7_monitoring_test
    step8_cleanup_and_summary
    
    log_success "ëª¨ë“  ëª¨ë‹ˆí„°ë§ ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main "$@"
